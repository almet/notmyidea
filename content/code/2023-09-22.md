---
tags: llm
---
# How to run the vigogne model locally

[Vigogne](https://github.com/bofenghuang/vigogne) is a LLM model based on LLAMA2, but trained with french data. As I'm working mostly in french, it might be useful. The current models that I can get locally are in english.

The information I've found online are scarse and not so easy to follow, so here is a step by step tutorial you can follow. I'm using [pipenv](https://pipenv.pypa.io/en/latest/) almost everywhere now, it's so easy :-)

```bash

llm install -U llm-llama-cpp
wget https://huggingface.co/TheBloke/Vigogne-2-7B-Chat-GGUF/resolve/main/vigogne-2-7b-chat.Q4_K_M.gguf
llm llama-cpp add-model vigogne-2-7b-chat.Q4_K_M.gguf -a vigogne
llm models default vigogne
```
